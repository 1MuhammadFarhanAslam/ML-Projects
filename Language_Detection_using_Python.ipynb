{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPUOTXMLsqGbZ8K9SOYLb14",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1MuhammadFarhanAslam/ML-Projects/blob/main/Language_Detection_using_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overview**\n",
        "\n",
        "**The dataset that I am using is collected from Kaggle, which contains data about 22 popular languages and contains 1000 sentences in each of the languages, so it will be an appropriate dataset for training a language detection model with machine learning.**"
      ],
      "metadata": {
        "id": "Dy9wEWJkkPKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv\")\n",
        "\n",
        "# Print the first five rows of the data\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "oR8Ey7bBkPqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s have a look at whether this dataset contains any null values or not:"
      ],
      "metadata": {
        "id": "19rtImvT1r-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "e3AOkhTo1kJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s have a look at all the languages present in this dataset:"
      ],
      "metadata": {
        "id": "9NNvGete1-Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['language'].value_counts()"
      ],
      "metadata": {
        "id": "n_STeySv1yxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['language'].value_counts().count()"
      ],
      "metadata": {
        "id": "cYk-A8Xk2J2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains 22 languages with 1000 sentences from each language. This is a very balanced dataset with no missing values, so we can say this dataset is completely ready to be used to train a machine learning model."
      ],
      "metadata": {
        "id": "wxDk219G20_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Language Detection Model**"
      ],
      "metadata": {
        "id": "Q2e0iiKI236J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a NumPy array of the text data\n",
        "x = np.array(data[\"Text\"])\n",
        "\n",
        "# Create a NumPy array of the language labels\n",
        "y = np.array(data[\"language\"])\n",
        "\n",
        "# Create an instance of the CountVectorizer class\n",
        "cv = CountVectorizer()\n",
        "\n",
        "# Convert the text data into a sparse matrix\n",
        "X = cv.fit_transform(x)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "kAI381H-2VM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "j4jNPsHB5xR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the MultinomialNB class\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "score = model.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "L_chVBeL6doS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "LN6vxXZ06yfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "id": "i1JfjhkW6zF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s use this model to detect the language of a text by taking a user input:"
      ],
      "metadata": {
        "id": "XBvkYDLy7yvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = input(\"Enter your text here: \")\n",
        "data = cv.transform([user]).toarray()\n",
        "output = model.predict(data)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "kllw_A9M6_aV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}